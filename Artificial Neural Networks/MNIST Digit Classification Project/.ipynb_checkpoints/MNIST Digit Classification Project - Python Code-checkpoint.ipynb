{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a869fca2",
   "metadata": {},
   "source": [
    "# MNIST Digit Classification Project - Python Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921d6384",
   "metadata": {},
   "source": [
    "Steve Desilets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4e7e1b",
   "metadata": {},
   "source": [
    "October 8, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f42feb",
   "metadata": {},
   "source": [
    "## 1) Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4205f7bb",
   "metadata": {},
   "source": [
    "For this project, we will be constructing models capable of classifying images of hand-drawn digits as the appropriate number (from 0 throuh 9).  To achieve this objective, we will construct several artificial neural network (ANN) models, an ANN model that leverages input data derived from principal components analysis (PCA), and a Random Forest Classifier model. For each of these models, we'll examine performance metrics as well as the key features that the models extracted during the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838a908",
   "metadata": {},
   "source": [
    "## 2) Importing Data, Conducting Exploratory Data Analysis, and Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec582256",
   "metadata": {},
   "source": [
    "### 2.1) Notebook Set-Up and Data Importation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94243e90",
   "metadata": {},
   "source": [
    "First, let's download the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f0e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from packaging import version\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl  # EA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow.keras.backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c54ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a5e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This notebook requires TensorFlow 2.0 or above\")\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e7ad8e",
   "metadata": {},
   "source": [
    "Now let's mount to the Google Colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e25d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d9226",
   "metadata": {},
   "source": [
    "Let's define functions that will be useful throughout the model development and assessment process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6458e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_validation_report(test_labels, predictions):\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(test_labels, predictions))\n",
    "    print('Accuracy Score: {}'.format(accuracy_score(test_labels, predictions)))\n",
    "    print('Root Mean Square Error: {}'.format(np.sqrt(MSE(test_labels, predictions))))\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    mtx = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(16,12))\n",
    "    sns.heatmap(mtx, annot=True, fmt='d', linewidths=.75,  cbar=False, ax=ax,cmap='Blues',linecolor='white')\n",
    "    #  square=True,\n",
    "    plt.ylabel('true label')\n",
    "    plt.xlabel('predicted label')\n",
    "\n",
    "def plot_history(history):\n",
    "  losses = history.history['loss']\n",
    "  accs = history.history['accuracy']\n",
    "  val_losses = history.history['val_loss']\n",
    "  val_accs = history.history['val_accuracy']\n",
    "  epochs = len(losses)\n",
    "\n",
    "  plt.figure(figsize=(16, 4))\n",
    "  for i, metrics in enumerate(zip([losses, accs], [val_losses, val_accs], ['Loss', 'Accuracy'])):\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    plt.plot(range(epochs), metrics[0], label='Training {}'.format(metrics[2]))\n",
    "    plt.plot(range(epochs), metrics[1], label='Validation {}'.format(metrics[2]))\n",
    "    plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "def plot_digits(instances, pos, images_per_row=5, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    pos.imshow(image, cmap = 'binary', **options)\n",
    "    pos.axis(\"off\")\n",
    "\n",
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = 'hot',\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731ae460",
   "metadata": {},
   "source": [
    "Let's load the MNIST dataset into this Python notebook.\n",
    "\n",
    "The MNIST dataset of handwritten digits has a training set of 60,000 images, and a test set of 10,000 images. It comes prepackaged as part of `tf.Keras`. We will load this dataset and the corresponding labels as Numpy arrays.\n",
    "\n",
    "* Tuples of Numpy arrays: `(x_train, y_train)`, `(x_test, y_test)`\n",
    "* `x_train`, `x_test`: uint8 arrays of grayscale image data with shapes (num_samples, 28, 28).\n",
    "* `y_train`, `y_test`: uint8 arrays of digit labels (integers in range 0-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70022b1",
   "metadata": {},
   "source": [
    "### 2.2) Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fba67d",
   "metadata": {},
   "source": [
    "Let's perform exploratory data analysis on the imported MNIST data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f12a2dc",
   "metadata": {},
   "source": [
    "Let's examine the shape of our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('x_train:\\t{}'.format(x_train.shape))\n",
    "print('y_train:\\t{}'.format(y_train.shape))\n",
    "print('x_test:\\t\\t{}'.format(x_test.shape))\n",
    "print('y_test:\\t\\t{}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1235cf",
   "metadata": {},
   "source": [
    "Let's print the first 10 labels in our training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fffcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First ten labels training dataset:\\n {}\\n\".format(y_train[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00951fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First ten labels training dataset:\\n {}\\n\".format(y_test[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9c4fc3",
   "metadata": {},
   "source": [
    "Let's examine the distribution of label values in our training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ce0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12 ,8))\n",
    "items = [{'Class': x, 'Count': y} for x, y in Counter(y_test).items()]\n",
    "distribution = pd.DataFrame(items).sort_values(['Class'])\n",
    "sns.barplot(x=distribution.Class, y=distribution.Count);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d669aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12 ,8))\n",
    "items = [{'Class': x, 'Count': y} for x, y in Counter(y_train).items()]\n",
    "distribution = pd.DataFrame(items).sort_values(['Class'])\n",
    "sns.barplot(x=distribution.Class, y=distribution.Count);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b13bf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_train).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd89029",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_test).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474ead22",
   "metadata": {},
   "source": [
    "Let's examine the first fifty images in the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b859d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15, 9))\n",
    "\n",
    "for i in range(50):\n",
    "    plt.subplot(5, 10, 1+i)\n",
    "    plt.title(y_train[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(x_train[i].reshape(28,28), cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf94c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15, 9))\n",
    "\n",
    "for i in range(50):\n",
    "    plt.subplot(5, 10, 1+i)\n",
    "    plt.title(y_train[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(x_test[i].reshape(28,28), cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a0275",
   "metadata": {},
   "source": [
    "### 2.3) Data Cleaning and Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b96e505",
   "metadata": {},
   "source": [
    "* Before we build our model, we need to prepare the data into the shape the network expected\n",
    "* More specifically, we will convert the labels (integers 0 to 9) to 1D numpy arrays of shape (10,) with elements 0s and 1s.\n",
    "* We also reshape the images from 2D arrays of shape (28,28) to 1D *float32* arrays of shape (784,) and then rescale their elements to values between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53081925",
   "metadata": {},
   "source": [
    "##### Let's apply one-hot coding to the labels.\n",
    "\n",
    "We will change the way the labels are represented from numbers (0 to 9) to vectors (1D arrays) of shape (10, ) with all the elements set to 0 except the one which the label belongs to - which will be set to 1. For example:\n",
    "\n",
    "\n",
    "| original label | one-hot encoded label |\n",
    "|------|------|\n",
    "| 5 | [0 0 0 0 0 1 0 0 0 0] |\n",
    "| 7 | [0 0 0 0 0 0 0 1 0 0] |\n",
    "| 1 | [0 1 0 0 0 0 0 0 0 0] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d90a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "print(\"First ten entries of y_train:\\n {}\\n\".format(y_train[0:10]))\n",
    "print(\"First ten rows of one-hot y_train:\\n {}\".format(y_train_encoded[0:10,]))\n",
    "\n",
    "print(\"First ten entries of y_test:\\n {}\\n\".format(y_train[0:10]))\n",
    "print(\"First ten rows of one-hot y_test:\\n {}\".format(y_train_encoded[0:10,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f7c9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('y_train_encoded shape: ', y_train_encoded.shape)\n",
    "print('y_test_encoded shape: ', y_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeddd15",
   "metadata": {},
   "source": [
    "##### Reshape the images to 1D arrays\n",
    "\n",
    "Reshape the images from shape (28, 28) 2D arrays to shape (784, ) vectors (1D arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de54e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before reshape:\n",
    "print('x_train:\\t{}'.format(x_train.shape))\n",
    "print('x_test:\\t\\t{}'.format(x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07780144",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=np.inf)\n",
    "print(\"{}\".format(x_train[2020]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5006c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the images:\n",
    "x_train_reshaped = np.reshape(x_train, (60000, 784))\n",
    "x_test_reshaped = np.reshape(x_test, (10000, 784))\n",
    "\n",
    "# After reshape:\n",
    "print('x_train_reshaped shape: ', x_train_reshaped.shape)\n",
    "print('x_test_reshaped shape: ', x_test_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d86c81f",
   "metadata": {},
   "source": [
    "1. Each element in an image is a pixel value\n",
    "2. Pixel values range from 0 to 255\n",
    "3. 0 = White\n",
    "4. 255 = Black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f55458",
   "metadata": {},
   "source": [
    "Let's review thew unique values using the set from the first image in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b03c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(x_train_reshaped[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967a0529",
   "metadata": {},
   "source": [
    "##### Rescale the elements of the reshaped images\n",
    "\n",
    "Let's rescale the elements of the x_train_reshaped and x_test_reshaped datasets to be between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75b4e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm = x_train_reshaped.astype('float32') / 255\n",
    "x_test_norm = x_test_reshaped.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea3b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the first reshaped and normalized training image:\n",
    "print(set(x_train_norm[0]))\n",
    "print(set(x_test_norm[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6969d9",
   "metadata": {},
   "source": [
    "## 3) Experiment 1 - ANN with 1 Hidden Layer with 1 Node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bc2178",
   "metadata": {},
   "source": [
    "### 3.1) Construct Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6c70d9",
   "metadata": {},
   "source": [
    "Now that we've finished preprocessing our MNIST image data, let's construct our first artificial neural network to classify images as integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6afe06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k.clear_session()\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(input_shape=[784], units=128, activation = tf.nn.relu,kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "    Dense(name = \"output_layer\", units = 10, activation = tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a16965",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de97d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "               loss = 'categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15c8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.model.fit\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\n",
    "\n",
    "#tf.keras.callbacks.EarlyStopping\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x_train_norm\n",
    "    ,y_train_encoded\n",
    "    ,epochs = 200\n",
    "    ,validation_split=0.20\n",
    "    ,callbacks=[tf.keras.callbacks.ModelCheckpoint(\"DNN_model.h5\",save_best_only=True,save_weights_only=False)\n",
    "                ,tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686b0a72",
   "metadata": {},
   "source": [
    "### 3.2) Evaluate Model Performance on Testing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43182e2b",
   "metadata": {},
   "source": [
    "Now that we've fit our model, let's apply the model to the test dataset and subsequently evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37139106",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"DNN_model.h5\")\n",
    "print(f\"Test acc: {model.evaluate(x_test_norm, y_test_encoded)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa27bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, accuracy = model.evaluate(x_test_norm, y_test_encoded)\n",
    "# print('test set accuracy: ', accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fd3fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test_norm)\n",
    "print('shape of preds: ', preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95368c6a",
   "metadata": {},
   "source": [
    "As part of our model evaluation, let's look at the first 25 images by plotting the test set images along with their predicted and actual labels to understand how the trained model actually performed on specific example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b87425",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "\n",
    "start_index = 0\n",
    "\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    pred = np.argmax(preds[start_index + i])\n",
    "    actual = np.argmax(y_test_encoded[start_index + i])\n",
    "    col = 'g'\n",
    "    if pred != actual:\n",
    "        col = 'r'\n",
    "    plt.xlabel('i={} | pred={} | true={}'.format(start_index + i, pred, actual), color = col)\n",
    "    plt.imshow(x_test[start_index + i], cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af58cd95",
   "metadata": {},
   "source": [
    "Let's use `Matplotlib` to create 2 plots--displaying the training and validation loss (resp. accuracy) for each (training) epoch side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242f8797",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f10bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = history.history['loss']\n",
    "accs = history.history['accuracy']\n",
    "val_losses = history.history['val_loss']\n",
    "val_accs = history.history['val_accuracy']\n",
    "epochs = len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22648384",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df=pd.DataFrame(history_dict)\n",
    "history_df.tail().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a50a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_training_curves(training, validation, title, subplot):\n",
    "  ax = plt.subplot(subplot)\n",
    "  ax.plot(training)\n",
    "  ax.plot(validation)\n",
    "  ax.set_title('model '+ title)\n",
    "  ax.set_ylabel(title)\n",
    "  ax.set_xlabel('epoch')\n",
    "  ax.legend(['training', 'validation'])\n",
    "\n",
    "plt.subplots(figsize=(16,12))\n",
    "plt.tight_layout()\n",
    "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 211)\n",
    "display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84cca0e",
   "metadata": {},
   "source": [
    "Let's examine precision and recall performance metrics for each of the prediction classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b6fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1= model.predict(x_test_norm)\n",
    "pred1=np.argmax(pred1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b2c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_validation_report(y_test, pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fa4187",
   "metadata": {},
   "source": [
    "Let's create a table that visualizes the model output for each of the first 20 images. These outputs can be thought of as the model's expression of the probability that each image corresponds to each digit class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efe29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predicted classes:\n",
    "# pred_classes = model.predict_classes(x_train_norm)# give deprecation warning\n",
    "pred_classes = np.argmax(model.predict(x_test_norm), axis=-1)\n",
    "pred_classes;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7806315",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Correlation matrix that measures the linear relationships</b><br>\n",
    "    https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37829175",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mx = tf.math.confusion_matrix(y_test, pred_classes)\n",
    "conf_mx;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf1463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.light_palette((260, 75, 60), input=\"husl\", as_cmap=True)\n",
    "df = pd.DataFrame(preds[0:20], columns = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "df.style.format(\"{:.2%}\").background_gradient(cmap=cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21649b56",
   "metadata": {},
   "source": [
    "Let's create a confusion matrix that visualizes the model's performance on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b1c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test,pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### INSERT COMMENTARY ABOUT DIGITS COMMONLY MIS CLASSIFIED AND ADJUST CODE IN CELL BELOW TO REFLECT THAT ############\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269803a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_a, cl_b = 4, 9\n",
    "X_aa = x_test_norm[(y_test == cl_a) & (pred_classes == cl_a)]\n",
    "X_ab = x_test_norm[(y_test == cl_a) & (pred_classes == cl_b)]\n",
    "X_ba = x_test_norm[(y_test == cl_b) & (pred_classes == cl_a)]\n",
    "X_bb = x_test_norm[(y_test == cl_b) & (pred_classes == cl_b)]\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "p1 = plt.subplot(221)\n",
    "p2 = plt.subplot(222)\n",
    "p3 = plt.subplot(223)\n",
    "p4 = plt.subplot(224)\n",
    "\n",
    "plot_digits(X_aa[:25], p1, images_per_row=5);\n",
    "plot_digits(X_ab[:25], p2, images_per_row=5);\n",
    "plot_digits(X_ba[:25], p3, images_per_row=5);\n",
    "plot_digits(X_bb[:25], p4, images_per_row=5);\n",
    "\n",
    "\n",
    "p1.set_title(f\"{cl_a}'s classified as {cl_a}'s\")\n",
    "p2.set_title(f\"{cl_a}'s classified as {cl_b}'s\")\n",
    "p3.set_title(f\"{cl_b}'s classified as {cl_a}'s\")\n",
    "p4.set_title(f\"{cl_b}'s classified as {cl_b}'s\")\n",
    "\n",
    "# plt.savefig(\"error_analysis_digits_plot_EXP1_valid\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa84e2c",
   "metadata": {},
   "source": [
    "### 3.3) Examine Features Extracted by Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f69a9b5",
   "metadata": {},
   "source": [
    "To get the activation values of the hidden nodes, we need to create a new model, `activation_model`, that takes the same input as our current model but outputs the activation value of the hidden layer, i.e. of the hidden node. Then use the `predict` function to get the activation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd35d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the outputs of the 2 layers:\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "\n",
    "# Creates a model that will return these outputs, given the model input:\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "print(f\"There are {len(layer_outputs)} layers\")\n",
    "layer_outputs; # description of the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c61ca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the outputs of all the hidden nodes for each of the 60000 training images\n",
    "activations = activation_model.predict(x_train_norm)\n",
    "hidden_layer_activation = activations[0]\n",
    "output_layer_activations = activations[1]\n",
    "hidden_layer_activation.shape   #  each of the 128 hidden nodes has one activation value per training image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b069cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer_activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e708408",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The maximum activation value of the hidden nodes in the hidden layer is \\\n",
    "{hidden_layer_activation.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75dacd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some stats about the output layer as an aside...\n",
    "np.set_printoptions(suppress = True)  # display probabilities as decimals and NOT in scientific notation\n",
    "ouput_layer_activation = activations[1]\n",
    "print(f\"The output node has shape {ouput_layer_activation.shape}\")\n",
    "print(f\"The output for the first image are {ouput_layer_activation[0].round(4)}\")\n",
    "print(f\"The sum of the probabilities is (approximately) {ouput_layer_activation[0].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e9e8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the dataframe of all the node values\n",
    "activation_data = {'actual_class':y_train}\n",
    "for k in range(0,128):\n",
    "    activation_data[f\"act_val_{k}\"] = hidden_layer_activation[:,k]\n",
    "\n",
    "activation_df = pd.DataFrame(activation_data)\n",
    "activation_df.head(15).round(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cfbcb0",
   "metadata": {},
   "source": [
    "Let's visualize these activiation values via boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa452be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see how closely the hidden node activation values correlate with the class labels\n",
    "# Let us use seaborn for the boxplots this time.\n",
    "plt.figure(figsize=(16,10))\n",
    "bplot = sns.boxplot(y='act_val_0', x='actual_class',\n",
    "                 data=activation_df[['act_val_0','actual_class']],\n",
    "                 width=0.5,\n",
    "                 palette=\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4345ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_df.groupby(\"actual_class\")[\"act_val_0\"].apply(lambda x: [round(min(x.tolist()),2),\n",
    " round(max(x.tolist()),2)]).reset_index().rename(columns={\"act_val_0\": \"range_of_act_values\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d7c008",
   "metadata": {},
   "source": [
    "Let's get activation values of the pixel values.\n",
    "\n",
    "We can create a dataframe with the pixel values and class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c89b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the dataframe of all the pixel values\n",
    "pixel_data = {'actual_class':y_train}\n",
    "for k in range(0,784):\n",
    "    pixel_data[f\"pix_val_{k}\"] = x_train_norm[:,k]\n",
    "pixel_df = pd.DataFrame(pixel_data)\n",
    "pixel_df.head(15).round(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1037cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_df.pix_val_77.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90df13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_df.pix_val_78.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30df6ea",
   "metadata": {},
   "source": [
    "Use a scatter plot to visualize the predicive power of the pixel values at two fixed locations in the image, i.e. how well the pixel values at two fixed locations in the image \"predict\" the class labels.\n",
    "\n",
    "We use a scatter plot to determine the correlation between the `pix_val_77` and `pix_val_78` values and the `actual_class` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12eaf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "color = sns.color_palette(\"hls\", 10)\n",
    "sns.scatterplot(x=\"pix_val_77\", y=\"pix_val_78\", hue=\"actual_class\",  palette=color, data = pixel_df, legend=\"full\")\n",
    "plt.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee39c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ab939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4e4000e",
   "metadata": {},
   "source": [
    "## 4) Experiment 2 - ANN with 1 Hidden Layer with 2 Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71235200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017b22b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1213f1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a62b664f",
   "metadata": {},
   "source": [
    "## 5)  Experiment 3 - ANN with 1 Hidden Layer with ______________________ Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2726a071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7036ad54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518de457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62aab111",
   "metadata": {},
   "source": [
    "## 6) Experiment 4 - ANN with 1 Hidden Layer with ___________________ Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628569ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6f50d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e9972e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1326bf1",
   "metadata": {},
   "source": [
    "## 7) Experiment 5 - ANN with 1 Hidden Layer with _________________________________ Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb51e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301a3d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abe2d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01f1b636",
   "metadata": {},
   "source": [
    "## 8) Experiment 6 - ANN with 1 Hidden Layer with _______________________________ Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972dc9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f445543d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec72924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7562d4a0",
   "metadata": {},
   "source": [
    "## 9) Experiment 7 - ANN with 1 Hidden Layer with ____________________________ Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c8604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e65d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f4c59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a77bef31",
   "metadata": {},
   "source": [
    "## 10) Experiment 8 - ANN with 1 Hidden Layer with __________________________ Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79323965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5242f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68050e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "437aae0d",
   "metadata": {},
   "source": [
    "## 11) Experiment 9 - Principal Components Analysis Followed By Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3079b2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e3131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b528e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00375839",
   "metadata": {},
   "source": [
    "## 12) Experiment 10 - Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e33057b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6499708a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e6406b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
